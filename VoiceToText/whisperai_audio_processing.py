# -*- coding: utf-8 -*-
"""WhisperAI_audio_processing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13jYWcaKOsd5MpiZqBoFhqS6PZv8rTLoP

# **Installing libraries and dependencies**

## **Installing whisperAI**
"""

!pip install torch

pip install -U openai-whisper

"""## **Updating package whisperAI to the latest version**"""

pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git

"""## **ffmpeg install**"""

!sudo apt update && sudo apt install ffmpeg

"""## **rust install**"""

pip install setuptools-rust

"""# **Audio data input and processing (Automatic language detection and base model)**"""

import os
from google.colab import drive
import whisper

# Montar Google Drive
drive.mount('/content/drive')

# Directorio donde están los archivos
carpeta = '/content/drive/MyDrive/whispersiafi'

# Cargar el modelo pre-entrenado
model = whisper.load_model("base")


# Iterar sobre los archivos en la carpeta
for archivo in os.listdir(carpeta):
    # Verificar que el elemento es un archivo (no un directorio)
    if os.path.isfile(os.path.join(carpeta, archivo)):
        # Obtenemos la ruta completa del archivo
        ruta_completa = os.path.join(carpeta, archivo)

        # Cargar el audio y ajustarlo a 30 segundos de duración
        audio = whisper.load_audio(ruta_completa)
        audio = whisper.pad_or_trim(audio)

        # Crear el espectrograma de Mel logarítmico y moverlo al mismo dispositivo que el modelo
        mel = whisper.log_mel_spectrogram(audio).to(model.device)

        # Detectar el idioma hablado
        _, probs = model.detect_language(mel)
        print(f"Idioma detectado en {archivo}: {max(probs, key=probs.get)}")

        # Decodificar el audio
        options = whisper.DecodingOptions()
        result = whisper.decode(model, mel, options)

        # Imprimir el texto reconocido
        print(f"Texto reconocido en {archivo}: {result.text}")

"""#**Spanish Language Specified Analysis in Whisper with different models**

##**Spanish Language Specified Analysis in Whisper Code (small model)**
"""

import os
from google.colab import drive
import whisper

# Montar Google Drive
drive.mount('/content/drive')

# Directorio donde están los archivos
carpeta = '/content/drive/MyDrive/whispersiafi'

# Cargar el modelo pre-entrenado "small"
model = whisper.load_model("small")

# Definir el idioma como español
model.language = "spanish"

# Iterar sobre los archivos en la carpeta
for archivo in os.listdir(carpeta):
    # Verificar que el elemento es un archivo (no un directorio)
    if os.path.isfile(os.path.join(carpeta, archivo)):
        # Obtener la ruta completa del archivo
        ruta_completa = os.path.join(carpeta, archivo)

        # Cargar el audio y ajustarlo a 30 segundos de duración
        audio = whisper.load_audio(ruta_completa)
        audio = whisper.pad_or_trim(audio)

        # Crear el espectrograma de Mel logarítmico y moverlo al mismo dispositivo que el modelo
        mel = whisper.log_mel_spectrogram(audio).to(model.device)

        # Decodificar el audio
        options = whisper.DecodingOptions()
        result = whisper.decode(model, mel, options)

        # Imprimir el texto reconocido
        print(f"Texto reconocido en {archivo}: {result.text}")

"""##**Spanish Language Specified Analysis in Whisper Code (base model)**"""

import os
from google.colab import drive
import whisper

# Montar Google Drive
drive.mount('/content/drive')

# Directorio donde están los archivos
carpeta = '/content/drive/MyDrive/whispersiafi'

# Cargar el modelo pre-entrenado
model = whisper.load_model("base")

# Establecer el idioma a español
model.language = "spanish"

# Iterar sobre los archivos en la carpeta
for archivo in os.listdir(carpeta):
    # Verificar que el elemento es un archivo (no un directorio)
    if os.path.isfile(os.path.join(carpeta, archivo)):
        # Obtenemos la ruta completa del archivo
        ruta_completa = os.path.join(carpeta, archivo)

        # Cargar el audio y ajustarlo a 30 segundos de duración
        audio = whisper.load_audio(ruta_completa)
        audio = whisper.pad_or_trim(audio)

        # Crear el espectrograma de Mel logarítmico y moverlo al mismo dispositivo que el modelo
        mel = whisper.log_mel_spectrogram(audio).to(model.device)

        # Decodificar el audio
        options = whisper.DecodingOptions()
        result = whisper.decode(model, mel, options)

        # Imprimir el texto reconocido
        print(f"Texto reconocido en {archivo}: {result.text}")

"""##**Spanish Language Specified Analysis in Whisper Code (large model)**"""

import os
from google.colab import drive
import whisper

# Montar Google Drive
drive.mount('/content/drive')

# Directorio donde están los archivos
carpeta = '/content/drive/MyDrive/whispersiafi'

# Cargar el modelo pre-entrenado
model = whisper.load_model("large")

# Establecer el idioma a español
model.language = "spanish"

# Iterar sobre los archivos en la carpeta
for archivo in os.listdir(carpeta):
    # Verificar que el elemento es un archivo (no un directorio)
    if os.path.isfile(os.path.join(carpeta, archivo)):
        # Obtenemos la ruta completa del archivo
        ruta_completa = os.path.join(carpeta, archivo)

        # Cargar el audio y ajustarlo a 30 segundos de duración
        audio = whisper.load_audio(ruta_completa)
        audio = whisper.pad_or_trim(audio)

        # Crear el espectrograma de Mel logarítmico y moverlo al mismo dispositivo que el modelo
        mel = whisper.log_mel_spectrogram(audio).to(model.device)

        # Decodificar el audio
        options = whisper.DecodingOptions()
        result = whisper.decode(model, mel, options)

        # Imprimir el texto reconocido
        print(f"Texto reconocido en {archivo}: {result.text}")

"""# **Writing output text from base model to a txt file**"""

import os
from google.colab import drive
import whisper

# Mount google drive
drive.mount('/content/drive')

# Directory with audio files
Directory = '/content/drive/MyDrive/whispersiafi'

# load the >base< model
model = whisper.load_model("base")

# stablishing language
model.language = "spanish"

# list for saving results
results = []

# Iterate over all the files in the directory
for file_i in os.listdir(Directory):
    # verify that file is not a directory
    if os.path.isfile(os.path.join(Directory, file_i)):
        # obtain the complete path
        complete_path = os.path.join(Directory, file_i)

        # load and trim audio to just 30 seconds
        audio = whisper.load_audio(complete_path)
        audio = whisper.pad_or_trim(audio)

        # creating mel spectrogram
        mel = whisper.log_mel_spectrogram(audio).to(model.device)

        # Decodify audio
        options = whisper.DecodingOptions()
        result = whisper.decode(model, mel, options)

        # append results to the list
        results.append(f"{file_i} | {result.text}")

# Saving results as a txt file
with open("/content/resultados.txt", "w") as file:
    for result in results:
        file.write(result + "\n")

# Download txt from google colab
from google.colab import files
files.download("/content/resultados.txt")

results_tuple= tuple(results)
results_tuple


{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Agregar la ruta del directorio donde están los módulos\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import FastSpeech2\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_path = \"C:\\\\Users\\\\derec\\\\OneDrive\\\\Documents\\\\F-VOICE\\\\config\\\\F-VOICE\\\\\"\n",
    "\n",
    "preprocess_config = yaml.load(open(base_path+\"preprocess.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "model_config = yaml.load(open(base_path+\"model.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "train_config = yaml.load(open(base_path+\"train.yaml\", \"r\"), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = (preprocess_config, model_config, train_config)\n",
    "model = FastSpeech2(preprocess_config, model_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Capas para Congelar (Freeze)**\n",
    "Estas capas son menos dependientes del hablante y suelen encargarse de transformar el texto en representaciones internas o realizar tareas de bajo nivel que no necesitan ser reentrenadas para una nueva voz.\n",
    "\n",
    "1. **`encoder`**\n",
    "   - **`src_word_emb`**: Embedding de palabras o fonemas. Esta capa no depende del hablante, por lo que puedes congelarla.\n",
    "   - **`layer_stack` (todas las capas FFTBlock dentro del encoder)**: Estas capas procesan las representaciones de texto. Puedes congelarlas ya que no dependen del timbre o las características específicas del hablante.\n",
    "\n",
    "2. **`variance_adaptor`**\n",
    "   - **`pitch_embedding`** y **`energy_embedding`**: Estas embeddings se utilizan para la modulación del tono y la energía, y no necesitan ser ajustadas en la mayoría de los casos, por lo que puedes congelarlas.\n",
    "\n",
    "### **Capas para Descongelar (Fine-tuning)**\n",
    "Estas capas afectan directamente las características acústicas y prosódicas de la síntesis de voz, por lo que debes ajustarlas al nuevo hablante.\n",
    "\n",
    "1. **`variance_adaptor`**\n",
    "   - **`duration_predictor`**, **`pitch_predictor`**, **`energy_predictor`**: Estas capas controlan la duración, el tono y la energía de la voz, que son características críticas para la adaptación de la nueva voz, por lo que deben ser ajustadas. Descongélalas para que el modelo pueda aprender la prosodia específica del hablante.\n",
    "   \n",
    "2. **`decoder`**\n",
    "   - **`layer_stack` (todas las capas FFTBlock dentro del decoder)**: Estas capas convierten las representaciones internas en espectrogramas de salida, los cuales dependen directamente del estilo y las características del hablante. Es importante descongelarlas para que el modelo pueda ajustar estas capas a la nueva voz.\n",
    "   \n",
    "3. **`mel_linear`**: La capa que convierte la salida del decoder en espectrogramas mel. Descongelarla permitirá ajustar mejor la salida del modelo a las características del hablante.\n",
    "\n",
    "4. **`postnet`**: Esta red post-procesa el espectrograma generado por el modelo para mejorar la calidad de la salida de audio. Debes descongelar esta capa para ajustar el modelo a la nueva voz y obtener mejores resultados en la síntesis de audio.\n",
    "\n",
    "### **Resumen de Capas a Congelar y Descongelar:**\n",
    "\n",
    "- **Congelar**:\n",
    "  - **`encoder`** (todas las capas, incluyendo embeddings y FFTBlock)\n",
    "  - **`variance_adaptor.pitch_embedding`** y **`variance_adaptor.energy_embedding`**\n",
    "\n",
    "- **Descongelar**:\n",
    "  - **`variance_adaptor.duration_predictor`**, **`pitch_predictor`**, **`energy_predictor`**\n",
    "  - **`decoder.layer_stack` (todas las FFTBlock)**\n",
    "  - **`mel_linear`**\n",
    "  - **`postnet`**\n",
    "\n",
    "Este enfoque permite que el modelo mantenga sus representaciones generales de texto y fonemas, mientras ajusta las capas necesarias para generar las características de la voz y la prosodia del nuevo hablante.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastSpeech2(\n",
      "  (encoder): Encoder(\n",
      "    (src_word_emb): Embedding(120, 256, padding_idx=0)\n",
      "    (layer_stack): ModuleList(\n",
      "      (0-3): 4 x FFTBlock(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (w_ks): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (w_vs): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (softmax): Softmax(dim=2)\n",
      "          )\n",
      "          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(256, 1024, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (w_2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (variance_adaptor): VarianceAdaptor(\n",
      "    (duration_predictor): VariancePredictor(\n",
      "      (conv_layer): Sequential(\n",
      "        (conv1d_1): Conv(\n",
      "          (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        )\n",
      "        (relu_1): ReLU()\n",
      "        (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_1): Dropout(p=0.5, inplace=False)\n",
      "        (conv1d_2): Conv(\n",
      "          (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        )\n",
      "        (relu_2): ReLU()\n",
      "        (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (linear_layer): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "    (length_regulator): LengthRegulator()\n",
      "    (pitch_predictor): VariancePredictor(\n",
      "      (conv_layer): Sequential(\n",
      "        (conv1d_1): Conv(\n",
      "          (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        )\n",
      "        (relu_1): ReLU()\n",
      "        (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_1): Dropout(p=0.5, inplace=False)\n",
      "        (conv1d_2): Conv(\n",
      "          (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        )\n",
      "        (relu_2): ReLU()\n",
      "        (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (linear_layer): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "    (energy_predictor): VariancePredictor(\n",
      "      (conv_layer): Sequential(\n",
      "        (conv1d_1): Conv(\n",
      "          (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        )\n",
      "        (relu_1): ReLU()\n",
      "        (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_1): Dropout(p=0.5, inplace=False)\n",
      "        (conv1d_2): Conv(\n",
      "          (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        )\n",
      "        (relu_2): ReLU()\n",
      "        (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (linear_layer): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "    (pitch_embedding): Embedding(256, 256)\n",
      "    (energy_embedding): Embedding(256, 256)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (layer_stack): ModuleList(\n",
      "      (0-5): 6 x FFTBlock(\n",
      "        (slf_attn): MultiHeadAttention(\n",
      "          (w_qs): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (w_ks): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (w_vs): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (attention): ScaledDotProductAttention(\n",
      "            (softmax): Softmax(dim=2)\n",
      "          )\n",
      "          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (pos_ffn): PositionwiseFeedForward(\n",
      "          (w_1): Conv1d(256, 1024, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "          (w_2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
      "          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mel_linear): Linear(in_features=256, out_features=80, bias=True)\n",
      "  (postnet): PostNet(\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): ConvNorm(\n",
      "          (conv): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "        )\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1-3): 3 x Sequential(\n",
      "        (0): ConvNorm(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "        )\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): ConvNorm(\n",
      "          (conv): Conv1d(512, 80, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "        )\n",
      "        (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (src_word_emb): Embedding(120, 256, padding_idx=0)\n",
       "  (layer_stack): ModuleList(\n",
       "    (0-3): 4 x FFTBlock(\n",
       "      (slf_attn): MultiHeadAttention(\n",
       "        (w_qs): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (w_ks): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (w_vs): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (attention): ScaledDotProductAttention(\n",
       "          (softmax): Softmax(dim=2)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (pos_ffn): PositionwiseFeedForward(\n",
       "        (w_1): Conv1d(256, 1024, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "        (w_2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congelar todas las capas del encoder\n",
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceAdaptor(\n",
       "  (duration_predictor): VariancePredictor(\n",
       "    (conv_layer): Sequential(\n",
       "      (conv1d_1): Conv(\n",
       "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (relu_1): ReLU()\n",
       "      (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout_1): Dropout(p=0.5, inplace=False)\n",
       "      (conv1d_2): Conv(\n",
       "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (relu_2): ReLU()\n",
       "      (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout_2): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (linear_layer): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (length_regulator): LengthRegulator()\n",
       "  (pitch_predictor): VariancePredictor(\n",
       "    (conv_layer): Sequential(\n",
       "      (conv1d_1): Conv(\n",
       "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (relu_1): ReLU()\n",
       "      (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout_1): Dropout(p=0.5, inplace=False)\n",
       "      (conv1d_2): Conv(\n",
       "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (relu_2): ReLU()\n",
       "      (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout_2): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (linear_layer): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (energy_predictor): VariancePredictor(\n",
       "    (conv_layer): Sequential(\n",
       "      (conv1d_1): Conv(\n",
       "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (relu_1): ReLU()\n",
       "      (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout_1): Dropout(p=0.5, inplace=False)\n",
       "      (conv1d_2): Conv(\n",
       "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (relu_2): ReLU()\n",
       "      (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout_2): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (linear_layer): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (pitch_embedding): Embedding(256, 256)\n",
       "  (energy_embedding): Embedding(256, 256)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.variance_adaptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congelar las embeddings de pitch y energía\n",
    "model.variance_adaptor.pitch_embedding.weight.requires_grad = False\n",
    "model.variance_adaptor.energy_embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (layer_stack): ModuleList(\n",
       "    (0-5): 6 x FFTBlock(\n",
       "      (slf_attn): MultiHeadAttention(\n",
       "        (w_qs): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (w_ks): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (w_vs): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (attention): ScaledDotProductAttention(\n",
       "          (softmax): Softmax(dim=2)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (pos_ffn): PositionwiseFeedForward(\n",
       "        (w_1): Conv1d(256, 1024, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "        (w_2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "        (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizar solo los parámetros que se van a entrenar\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

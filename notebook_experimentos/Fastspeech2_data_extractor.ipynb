{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Agregar la ruta del directorio donde están los módulos\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from audio import audio as Audio #Viene del repo de fastspeech\n",
    "import pyworld as pw\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tgt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def remove_outlier(values):\n",
    "    values = np.array(values)\n",
    "    p25 = np.percentile(values, 25)\n",
    "    p75 = np.percentile(values, 75)\n",
    "    lower = p25 - 1.5 * (p75 - p25)\n",
    "    upper = p75 + 1.5 * (p75 - p25)\n",
    "    normal_indices = np.logical_and(values > lower, values < upper)\n",
    "\n",
    "    return values[normal_indices]\n",
    "\n",
    "def normalize(in_dir, mean, std):\n",
    "    max_value = np.finfo(np.float64).min\n",
    "    min_value = np.finfo(np.float64).max\n",
    "    for filename in os.listdir(in_dir):\n",
    "        filename = os.path.join(in_dir, filename)\n",
    "        values = (np.load(filename) - mean) / std\n",
    "        np.save(filename, values)\n",
    "\n",
    "        max_value = max(max_value, max(values))\n",
    "        min_value = min(min_value, min(values))\n",
    "\n",
    "    return min_value, max_value\n",
    "\n",
    "#Extraccion de expectogramas de mel\n",
    "def extract_mel_spectrogram(wav, stft,duration):\n",
    "    mel_spectrogram, energy = Audio.tools.get_mel_from_wav(wav, stft)\n",
    "    mel_spectrogram = mel_spectrogram[:, : sum(duration)]\n",
    "    energy = energy[: sum(duration)]\n",
    "    return mel_spectrogram, energy\n",
    "\n",
    "#Extraccion de pitch\n",
    "def extract_pitch(wav, sampling_rate, hop_length,duration):\n",
    "    # Usar DIO para obtener pitch\n",
    "    pitch, t = pw.dio(wav.astype(np.float64), sampling_rate, frame_period=hop_length / sampling_rate * 1000)\n",
    "    pitch = pw.stonemask(wav.astype(np.float64), pitch, t, sampling_rate)\n",
    "    pitch = pitch[: sum(duration)]\n",
    "    return pitch\n",
    "\n",
    "#Esta función se encarga de extraer \n",
    "# las duraciones desde el archivo .TextGrid\n",
    "def get_alignment(textgridsfile, sampling_rate, hop_length):\n",
    "    sil_phones = [\"sil\", \"sp\", \"spn\"]\n",
    "\n",
    "    phones = []\n",
    "    durations = []\n",
    "    start_time = 0\n",
    "    end_time = 0\n",
    "    end_idx = 0\n",
    "    \n",
    "    for t in textgridsfile._objects:\n",
    "        s, e, p = t.start_time, t.end_time, t.text\n",
    "\n",
    "        # Trim leading silences (eliminar silencios al principio)\n",
    "        if phones == []:\n",
    "            if p in sil_phones:\n",
    "                continue\n",
    "            else:\n",
    "                start_time = s\n",
    "\n",
    "        if p not in sil_phones:\n",
    "            # Fonemas ordinarios\n",
    "            phones.append(p)\n",
    "            end_time = e\n",
    "            end_idx = len(phones)\n",
    "        else:\n",
    "            # Fonemas silenciosos\n",
    "            phones.append(p)\n",
    "\n",
    "        # Calcular las duraciones de los fonemas en frames\n",
    "        durations.append(\n",
    "            int(np.round(e * sampling_rate / hop_length) - np.round(s * sampling_rate / hop_length))\n",
    "        )\n",
    "\n",
    "    # Eliminar los silencios al final\n",
    "    phones = phones[:end_idx]\n",
    "    durations = durations[:end_idx]\n",
    "\n",
    "    return phones, durations, start_time, end_time\n",
    "\n",
    "#Preprocesa un audio para obtener las carecateristicas escenciales\n",
    "#como el Mel, pitch, energy y duration\n",
    "\n",
    "def process_audio(wav_path,text_path,basename,out_dir,tg_path, sampling_rate, hop_length, stft):\n",
    "    # Leer el archivo de audio\n",
    "    wav, _ = librosa.load(wav_path)\n",
    "    \n",
    "    # Leer y obtener alineaciones\n",
    "    textgrid = tgt.io.read_textgrid(tg_path)\n",
    "    phone, duration, start, end = get_alignment(textgrid.get_tier_by_name(\"phones\"), sampling_rate, hop_length)\n",
    "    text = \"{\" + \" \".join(phone) + \"}\"\n",
    "    if start >= end:\n",
    "            return None\n",
    "    # Cortar el audio basado en el tiempo de inicio y fin\n",
    "    wav = wav[int(sampling_rate * start): int(sampling_rate * end)].astype(np.float32)\n",
    "    # Read raw text\n",
    "    with open(text_path, \"r\") as f:\n",
    "        raw_text = f.readline().strip(\"\\n\")\n",
    "    # Extraer espectrograma de Mel y energía\n",
    "    mel_spectrogram, energy = extract_mel_spectrogram(wav,stft,duration)\n",
    "    \n",
    "    # Extraer pitch\n",
    "    pitch = extract_pitch(wav, sampling_rate, hop_length,duration)\n",
    "    \n",
    "\n",
    "    #procesamiento de pitch\n",
    "     # Interpolación y Promedio de Pitch a Nivel de Fonema\n",
    "    nonzero_ids = np.where(pitch != 0)[0]\n",
    "    if len(nonzero_ids) > 0:\n",
    "            interp_fn = interp1d(\n",
    "            nonzero_ids,\n",
    "            pitch[nonzero_ids],\n",
    "            fill_value=(pitch[nonzero_ids[0]], pitch[nonzero_ids[-1]]),\n",
    "            bounds_error=False,)\n",
    "            pitch = interp_fn(np.arange(0, len(pitch)))\n",
    "            # Phoneme-level average\n",
    "            pos = 0\n",
    "            for i, d in enumerate(duration):\n",
    "                if d > 0:\n",
    "                    pitch[i] = np.mean(pitch[pos : pos + d])\n",
    "                else:\n",
    "                    pitch[i] = 0\n",
    "                pos += d\n",
    "            pitch = pitch[: len(duration)]\n",
    "    # Promedio de Energía a Nivel de Fonema\n",
    "    pos = 0\n",
    "    for i, d in enumerate(duration):\n",
    "        if d > 0:\n",
    "            energy[i] = np.mean(energy[pos : pos + d])\n",
    "        else:\n",
    "            energy[i] = 0\n",
    "            pos += d\n",
    "    energy = energy[: len(duration)]\n",
    "    # Guardar los archivos de duración, pitch, energía y espectrograma de Mel\n",
    "    dur_filename = \"{}-duration.npy\".format(basename)\n",
    "    np.save(os.path.join(out_dir, \"duration\", dur_filename), duration)\n",
    "\n",
    "    pitch_filename = \"{}-pitch.npy\".format(basename)\n",
    "    np.save(os.path.join(out_dir, \"pitch\", pitch_filename), pitch)\n",
    "\n",
    "    energy_filename = \"{}-energy.npy\".format(basename)\n",
    "    np.save(os.path.join(out_dir, \"energy\", energy_filename), energy)\n",
    "\n",
    "    mel_filename = \"{}-mel.npy\".format(basename)\n",
    "    np.save(os.path.join(out_dir, \"mel\", mel_filename), mel_spectrogram.T)\n",
    "    \n",
    "    return (\n",
    "            \"|\".join([basename, text, raw_text]),\n",
    "            remove_outlier(pitch),\n",
    "            remove_outlier(energy),\n",
    "            mel_spectrogram.shape[1],\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear carpetas para guardar las caracteristicas\n",
    "\n",
    "out_dir = \"/home/dereck125/Documentos/dereckpreprocessed\"\n",
    "os.makedirs((os.path.join(out_dir, \"mel\")), exist_ok=True)\n",
    "os.makedirs((os.path.join(out_dir, \"pitch\")), exist_ok=True)\n",
    "os.makedirs((os.path.join(out_dir, \"energy\")), exist_ok=True)\n",
    "os.makedirs((os.path.join(out_dir, \"duration\")), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando datos ...\n",
      "Computing statistic quantities ...\n",
      "Total time: 0.35468803224993706 hours\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "import random\n",
    "sr = 22050\n",
    "hl = 256\n",
    "val_size=100\n",
    "stft = Audio.stft.TacotronSTFT(\n",
    "    filter_length=1024,\n",
    "    hop_length=hl,\n",
    "    win_length=1024,\n",
    "    n_mel_channels=80,\n",
    "    sampling_rate=sr,\n",
    "    mel_fmin=0.0,\n",
    "    mel_fmax=8000.0,\n",
    ")\n",
    "\n",
    "print(\"Procesando datos ...\")\n",
    "out = list()\n",
    "n_frames = 0\n",
    "pitch_scaler = StandardScaler()\n",
    "energy_scaler = StandardScaler()\n",
    "#Obtener el pitch, energy, duration y mel-spectogram\n",
    "wav_directory = \"/home/dereck125/Documentos/dataset1/fvoice/\"\n",
    "for wav_name in os.listdir(wav_directory):\n",
    "    if \".wav\" not in wav_name:\n",
    "        continue\n",
    "    basename = wav_name.split(\".\")[0]\n",
    "    tg_path = os.path.join(\"/home/dereck125/Documentos/dataset1/dereck_align/\",\"{}.TextGrid\".format(basename))\n",
    "    text_path =os.path.join(wav_directory,\"{}.lab\".format(basename))\n",
    "    if os.path.exists(tg_path):\n",
    "        ret = process_audio(wav_directory+wav_name,text_path,basename,out_dir,tg_path, sr, hl, stft)\n",
    "        if ret is None:\n",
    "            continue\n",
    "        else:\n",
    "            info, pitch, energy, n = ret\n",
    "        out.append(info)\n",
    "    if len(pitch) > 0:\n",
    "        pitch_scaler.partial_fit(pitch.reshape((-1, 1)))\n",
    "    if len(energy) > 0:\n",
    "        energy_scaler.partial_fit(energy.reshape((-1, 1)))\n",
    "\n",
    "    n_frames += n\n",
    "print(\"Computing statistic quantities ...\")\n",
    "#pitch normalization\n",
    "pitch_mean = pitch_scaler.mean_[0]\n",
    "pitch_std = pitch_scaler.scale_[0]\n",
    "energy_mean = energy_scaler.mean_[0]\n",
    "energy_std = energy_scaler.scale_[0]\n",
    "\n",
    "pitch_min, pitch_max = normalize(\n",
    "            os.path.join(out_dir, \"pitch\"), pitch_mean, pitch_std\n",
    "        )\n",
    "energy_min, energy_max = normalize(\n",
    "            os.path.join(out_dir, \"energy\"), energy_mean, energy_std\n",
    "        )\n",
    "\n",
    "with open(os.path.join(out_dir, \"stats.json\"), \"w\") as f:\n",
    "            stats = {\n",
    "                \"pitch\": [\n",
    "                    float(pitch_min),\n",
    "                    float(pitch_max),\n",
    "                    float(pitch_mean),\n",
    "                    float(pitch_std),\n",
    "                ],\n",
    "                \"energy\": [\n",
    "                    float(energy_min),\n",
    "                    float(energy_max),\n",
    "                    float(energy_mean),\n",
    "                    float(energy_std),\n",
    "                ],\n",
    "            }\n",
    "            f.write(json.dumps(stats))\n",
    "print(\"Total time: {} hours\".format(\n",
    "                n_frames * hl / sr / 3600\n",
    "            )\n",
    "        )   \n",
    "\n",
    "#Crea los conjuntos de train y test \n",
    "random.shuffle(out)     \n",
    "\n",
    "out = [r for r in out if r is not None]\n",
    "\n",
    "# escribe los metadatos\n",
    "with open(os.path.join(out_dir, \"train.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    for m in out[val_size :]:\n",
    "        f.write(m + \"\\n\")\n",
    "with open(os.path.join(out_dir, \"val.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    for m in out[:val_size]:\n",
    "        f.write(m + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fassp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

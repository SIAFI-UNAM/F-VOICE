{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils_2 import TextMelLoader, TextMelCollate\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hparams = {\n",
    "    'training_files':'filelists/5_wavs.txt',\n",
    "    'validation_files':'filelists/5_wavs.txt',\n",
    "    'text_cleaners': ['english_cleaners'],\n",
    "    'max_wav_value': 32768.0,\n",
    "    'sampling_rate': 22050,\n",
    "    'load_mel_from_disk': False,\n",
    "    'filter_length': 1024,\n",
    "    'hop_length': 256,\n",
    "    'win_length': 1024,\n",
    "    'n_mel_channels': 80,\n",
    "    'mel_fmin': 0.0,\n",
    "    'mel_fmax': 8000.0,\n",
    "    'seed': 20,\n",
    "    'distributed_run':False,\n",
    "     ################################\n",
    "        # Optimization Hyperparameters #\n",
    "        ################################\n",
    "    'use_saved_learning_rate':False,\n",
    "    'learning_rate':1e-3,\n",
    "    'weight_decay':1e-6,\n",
    "    'grad_clip_thresh':1.0,\n",
    "    'batch_size':64,\n",
    "    'mask_padding':True  # set model's padded outputs to padded values\n",
    "}\n",
    "\n",
    "\n",
    "def prepare_dataloaders(hparams):\n",
    "    # Get data, data loaders and collate function ready\n",
    "    trainset = TextMelLoader(hparams['training_files'], hparams['text_cleaners'],\n",
    "                         hparams['max_wav_value'], hparams['sampling_rate'],\n",
    "                         hparams['load_mel_from_disk'], hparams['filter_length'],\n",
    "                         hparams['hop_length'], hparams['win_length'],\n",
    "                         hparams['n_mel_channels'], hparams['mel_fmin'],\n",
    "                         hparams['mel_fmax'], hparams['seed'])\n",
    "    valset = TextMelLoader( hparams['validation_files'], hparams['text_cleaners'],\n",
    "                         hparams['max_wav_value'], hparams['sampling_rate'],\n",
    "                         hparams['load_mel_from_disk'], hparams['filter_length'],\n",
    "                         hparams['hop_length'], hparams['win_length'],\n",
    "                         hparams['n_mel_channels'], hparams['mel_fmin'],\n",
    "                         hparams['mel_fmax'], hparams['seed'])\n",
    "    collate_fn = TextMelCollate(n_frames_per_step=1)\n",
    "\n",
    "    if hparams['distributed_run']:\n",
    "        train_sampler = DistributedSampler(trainset)\n",
    "        shuffle = False\n",
    "    else:\n",
    "        train_sampler = None\n",
    "        shuffle = True\n",
    "\n",
    "    train_loader = DataLoader(trainset, num_workers=1, shuffle=shuffle,\n",
    "                              sampler=train_sampler,\n",
    "                              batch_size=hparams['batch_size'], pin_memory=False,\n",
    "                              drop_last=True, collate_fn=collate_fn)\n",
    "    return train_loader, valset, collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([57, 45, 42, 11, 46, 51, 59, 42, 51, 57, 46, 52, 51, 11, 52, 43, 11, 50,\n",
       "         52, 59, 38, 39, 49, 42, 11, 50, 42, 57, 38, 49, 11, 49, 42, 57, 57, 42,\n",
       "         55, 56, 11, 46, 51, 11, 57, 45, 42, 11, 50, 46, 41, 41, 49, 42, 11, 52,\n",
       "         43, 11, 57, 45, 42, 11, 43, 46, 43, 57, 42, 42, 51, 57, 45, 11, 40, 42,\n",
       "         51, 57, 58, 55, 62, 11, 50, 38, 62, 11, 47, 58, 56, 57, 49, 62, 11, 39,\n",
       "         42, 11, 40, 52, 51, 56, 46, 41, 42, 55, 42, 41, 11, 38, 56, 11, 57, 45,\n",
       "         42, 11, 46, 51, 59, 42, 51, 57, 46, 52, 51, 11, 52, 43, 11, 57, 45, 42,\n",
       "         11, 38, 55, 57, 11, 52, 43, 11, 53, 55, 46, 51, 57, 46, 51, 44,  7],\n",
       "        dtype=torch.int32),\n",
       " tensor([[-9.1835, -6.4719, -6.0837,  ..., -7.4548, -7.7138, -7.3676],\n",
       "         [-6.7287, -6.1699, -6.1468,  ..., -6.8450, -7.2991, -6.9986],\n",
       "         [-5.8363, -5.4046, -5.2813,  ..., -6.3080, -6.4373, -6.1320],\n",
       "         ...,\n",
       "         [-6.1044, -5.9024, -5.3051,  ..., -9.3646, -9.5347, -9.8833],\n",
       "         [-5.6057, -5.5987, -5.1356,  ..., -9.2024, -9.3682, -9.8212],\n",
       "         [-7.6790, -7.2099, -5.6514,  ..., -9.5265, -9.3538, -9.9673]]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t,v,c =prepare_dataloaders(hparams)\n",
    "v.get_mel_text_pair(v.audiopaths_and_text[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
